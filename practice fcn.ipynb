{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_kernel_size(factor):\n",
    "    return 2*factor - factor%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upsample_filt(size):\n",
    "    factor=(size+1)//2\n",
    "    if size % 2 == 1:\n",
    "        center = factor -1\n",
    "    else:\n",
    "        center = factor - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upsample_filt(size):\n",
    "    \"\"\"\n",
    "    Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "    \"\"\"\n",
    "    factor = (size + 1) // 2\n",
    "    if size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:size, :size]\n",
    "    return (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilinear_upsample_weights(factor, number_of_classes):\n",
    "    \"\"\"\n",
    "    Create weights matrix for transposed convolution with bilinear filter\n",
    "    initialization.\n",
    "    \"\"\"\n",
    "    \n",
    "    filter_size = get_kernel_size(factor)\n",
    "    \n",
    "    weights = np.zeros((filter_size,\n",
    "                        filter_size,\n",
    "                        number_of_classes,\n",
    "                        number_of_classes), dtype=np.float32)\n",
    "    \n",
    "    upsample_kernel = upsample_filt(filter_size)\n",
    "    \n",
    "    for i in xrange(number_of_classes):\n",
    "        \n",
    "        weights[:, :, i, i] = upsample_kernel\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "image_filename = 'data/imgs/cat.jpg'\n",
    "annotation_filename = 'data/imgs/cat_annotation.png'\n",
    "\n",
    "image_filename_placeholder = tf.placeholder(tf.string)\n",
    "annotation_filename_placeholder = tf.placeholder(tf.string)\n",
    "is_training_placeholder = tf.placeholder(tf.bool)\n",
    "\n",
    "feed_dict_to_use = {image_filename_placeholder: image_filename,\n",
    "                    annotation_filename_placeholder: annotation_filename,\n",
    "                    is_training_placeholder: True}\n",
    "\n",
    "image_tensor = tf.read_file(image_filename_placeholder)\n",
    "annotation_tensor = tf.read_file(annotation_filename_placeholder)\n",
    "\n",
    "image_tensor = tf.image.decode_jpeg(image_tensor, channels=3)\n",
    "annotation_tensor = tf.image.decode_png(annotation_tensor, channels=1)\n",
    "\n",
    "# Get ones for each class instead of a number -- we need that\n",
    "# for cross-entropy loss later on. Sometimes the groundtruth\n",
    "# masks have values other than 1 and 0. \n",
    "class_labels_tensor = tf.equal(annotation_tensor, 1)\n",
    "background_labels_tensor = tf.not_equal(annotation_tensor, 1)\n",
    "\n",
    "# Convert the boolean values into floats -- so that\n",
    "# computations in cross-entropy loss is correct\n",
    "bit_mask_class = tf.to_float(class_labels_tensor)\n",
    "bit_mask_background = tf.to_float(background_labels_tensor)\n",
    "\n",
    "combined_mask = tf.concat(concat_dim=2, values=[bit_mask_class,\n",
    "                                                bit_mask_background])\n",
    "\n",
    "# Lets reshape our input so that it becomes suitable for \n",
    "# tf.softmax_cross_entropy_with_logits with [batch_size, num_classes]\n",
    "flat_labels = tf.reshape(tensor=combined_mask, shape=(-1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig_size = [15,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named nets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-fda31cad2365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named nets"
     ]
    }
   ],
   "source": [
    "from nets import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named preprocessing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a68453b601d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvgg_preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named preprocessing"
     ]
    }
   ],
   "source": [
    "from preprocessing import vgg_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upsample_factor = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_float = tf.to_float(image_tensor, name='ToFloat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_mean_image_subtraction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5aab5a1e36cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_centered_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mean_image_subtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_R_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_G_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_B_MEAN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '_mean_image_subtraction' is not defined"
     ]
    }
   ],
   "source": [
    "mean_centered_image = _mean_image_subtraction(image_float, [_R_MEAN, _G_MEAN, _B_MEAN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named datasets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-40582ccbe6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named datasets"
     ]
    }
   ],
   "source": [
    "from datasets import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
